{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Classificador Automático de Sentimento\n",
    "\n",
    "Você foi contratado por uma empresa parar analisar como os clientes estão reagindo a um determinado produto no Twitter. A empresa deseja que você crie um programa que irá analisar as mensagens disponíveis e classificará como \"relevante\" ou \"irrelevante\". Com isso ela deseja que mensagens negativas, que denigrem o nome do produto, ou que mereçam destaque, disparem um foco de atenção da área de marketing.<br /><br />\n",
    "Como aluno de Ciência dos Dados, você lembrou do Teorema de Bayes, mais especificamente do Classificador Naive-Bayes, que é largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser relevante dadas as palavras em seu conteúdo.<br /><br />\n",
    "Para realizar o MVP (*minimum viable product*) do projeto, você precisa implementar uma versão do classificador que \"aprende\" o que é relevante com uma base de treinamento e compara a performance dos resultados com uma base de testes.<br /><br />\n",
    "Após validado, o seu protótipo poderá também capturar e classificar automaticamente as mensagens da plataforma.\n",
    "\n",
    "## Informações do Projeto\n",
    "\n",
    "Prazo: 19/Set até às 23:59.<br />\n",
    "Grupo: 2 ou 3 pessoas - grupos com 3 pessoas terá uma rubrica diferenciada.<br /><br />\n",
    "Entregáveis via GitHub: \n",
    "* Arquivo notebook com o código do classificador, seguindo as orientações abaixo.\n",
    "* Arquivo Excel com as bases de treinamento e teste totalmente classificado.\n",
    "\n",
    "**NÃO gravar a key do professor no arquivo**\n",
    "\n",
    "\n",
    "### Entrega Intermediária: Check 1 - APS 2\n",
    "\n",
    "Até o dia 10/Set às 23:59, xlsx deve estar no Github com as seguintes evidências: \n",
    "\n",
    "  * Produto escolhido.\n",
    "  * Arquivo Excel contendo a base de treinamento e a base de testes já classificadas.\n",
    "\n",
    "Sugestão de leitura:<br />\n",
    "https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Parte I - Adquirindo a Base de Dados\n",
    "\n",
    "Acessar o notebook **Projeto-2-Planilha** para realizar a coleta dos dados. O grupo deve classificar os dados coletados manualmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Parte II - Montando o Classificador Naive-Bayes\n",
    "\n",
    "Com a base de treinamento montada, comece a desenvolver o classificador. Não se esqueça de implementar o Laplace Smoothing (https://en.wikipedia.org/wiki/Laplace_smoothing).\n",
    "\n",
    "Opcionalmente: \n",
    "* Limpar as mensagens removendo os caracteres: enter, :, \", ', (, ), etc. Não remover emojis.<br />\n",
    "* Corrigir separação de espaços entre palavras e/ou emojis.\n",
    "* Propor outras limpezas/transformações que não afetem a qualidade da informação.\n",
    "\n",
    "Escreva o seu código abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "treinamento = pd.read_excel('spiderman.xlsx', sheet_name='Treinamento')\n",
    "teste = pd.read_excel('spiderman.xlsx', sheet_name='Teste')\n",
    "\n",
    "dfs = [treinamento,teste]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "tempo_incial = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_message(tweet):\n",
    "    tweet = tweet.lower()\n",
    "\n",
    "    \n",
    "    space_around = [\"?\",\"!\"]\n",
    "    for i in space_around:\n",
    "        tweet = tweet.replace(i, \" \" + i + \" \")\n",
    "\n",
    "    \n",
    "    space = [\",\", \";\", \"\\n\", \"\\xa0\",\"\\x00\", '\"', \"(\", \")\", \"“\", \"”\"]\n",
    "    for k in space:\n",
    "        tweet = tweet.replace(k,\" \")\n",
    "    \n",
    "    \n",
    "    remove = [\"'\", \"…\", \"*\", \"’\", \"‘\", '️']\n",
    "    for j in remove:\n",
    "        tweet = tweet.replace(j,\"\")\n",
    " \n",
    "\n",
    "    tweet = tweet.split(\" \")\n",
    "\n",
    "    \n",
    "    space_link = [\"-\", \":\", \".\", \"/\"]\n",
    "    \n",
    "    for i in range(0,len(tweet))[::-1]:\n",
    "        if tweet[i] == \"\":\n",
    "            tweet.pop(i)\n",
    "        \n",
    "        elif \"http\" in tweet[i] or \"https\" in tweet[i]:\n",
    "            tweet.pop(i)\n",
    "        else:\n",
    "            for l in space_link:\n",
    "                tweet[i] = tweet[i].replace(l,\" \")\n",
    "    \n",
    "    tweet = \" \".join(tweet)\n",
    "    tweet = tweet.split(\" \")\n",
    "    for i in range(0,len(tweet))[::-1]:\n",
    "        if tweet[i] == \"\":\n",
    "            tweet.pop(i)\n",
    "    \n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R</th>\n",
       "      <th>I</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>spiderman</th>\n",
       "      <td>117.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>242.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rt</th>\n",
       "      <td>111.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>210.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>115.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>196.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>on</th>\n",
       "      <td>95.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>game</th>\n",
       "      <td>101.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               R      I  Total\n",
       "spiderman  117.0  125.0  242.0\n",
       "rt         111.0   99.0  210.0\n",
       "the        115.0   81.0  196.0\n",
       "on          95.0   45.0  140.0\n",
       "game       101.0   24.0  125.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_dfs = []\n",
    "\n",
    "for df, index in zip(dfs,range(len(dfs))):\n",
    "    col_name = df.columns[0]\n",
    "\n",
    "\n",
    "#   Cria uma coluna nova com tweets limpos\n",
    "    df[\"Separado\"] = df[col_name].apply(new_message)\n",
    "        \n",
    "        \n",
    "#   Soma das listas de cada tweet, gerando uma lista imensa que contém todas as palavras;\n",
    "#   Usa value_counts para contar a ocorrencia de cada palavra;\n",
    "#   Transforma em uma nova dataframe\n",
    "    R = pd.Series(df[df[\"Relevância\"]==\"R\"][\"Separado\"].sum())\\\n",
    "                    .value_counts().to_frame().rename(columns = {0 : \"R\"})\n",
    "    \n",
    "    I = pd.Series(df[df[\"Relevância\"]==\"I\"][\"Separado\"].sum())\\\n",
    "                    .value_counts().to_frame().rename(columns = {0 : \"I\"})\n",
    "\n",
    "#   Junta as dataframes R e I e substitui os NaN por 0\n",
    "    joined = R.join(I, how = \"outer\").fillna(0)\n",
    "    \n",
    "    joined[\"Total\"] = joined[\"R\"] + joined[\"I\"]\n",
    "    joined.sort_values(by = \"Total\" , ascending = False, inplace = True)\n",
    "\n",
    "    words_dfs.append(joined)\n",
    "\n",
    "\n",
    "treinamento_fin , teste_fin = words_dfs\n",
    "\n",
    "treinamento_fin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Acha a quantidade de palavras relevantes, de palavras irrelevantes, \n",
    "# de palavras no total e quantas palavras diferentes tem no dataFrame\n",
    "\n",
    "somrel = treinamento_fin[\"R\"].sum()\n",
    "somirrel = treinamento_fin[\"I\"].sum()\n",
    "\n",
    "somtot = somrel + somirrel\n",
    "\n",
    "n = treinamento_fin.index.size\n",
    "\n",
    "# Probabilidade de um tweet ser relevante e de ser irrelevante\n",
    "probrel =   somrel / somtot\n",
    "probirr = somirrel / somtot\n",
    "\n",
    "from collections import defaultdict as ddict\n",
    "def count_words(l):\n",
    "    d = ddict(int)\n",
    "    for i in l:\n",
    "        d[i] += 1\n",
    "    return d\n",
    "    \n",
    "def verifica_relevancia(Tweet):\n",
    "    if type(Tweet) == str:\n",
    "        # Splita e limpa o tweet caso o tweet não seja uma lista,\n",
    "        # o que permite a função funcionar com tweets inserido em lista ou em string \n",
    "        Tweet = new_message(Tweet)\n",
    "    \n",
    "    # Transforma a lista em um dicionário para evitar procurar\n",
    "    # a mesma palvavra mais de uma vez no dataframe\n",
    "    Tweet = count_words(Tweet)\n",
    "    \n",
    "    # Para inicio do produtório\n",
    "    probPal = 1\n",
    "    ProbPal = 1\n",
    "    \n",
    "    # Probabilidade de ser relevante (ou irrelevante) dado que é tweet com Laplace smoothing\n",
    "    for i in Tweet:\n",
    "        if treinamento_fin.index.contains(i):\n",
    "            probpal = (treinamento_fin[\"R\"][i] + 1) / (somrel + n)\n",
    "            Probpal = (treinamento_fin[\"I\"][i] + 1) / (somirrel + n)\n",
    "        else:\n",
    "            probpal = 1 / (somrel + n)\n",
    "            Probpal = 1 / (somirrel + n)\n",
    "\n",
    "        probPal *= probpal**Tweet[i]\n",
    "        ProbPal *= Probpal**Tweet[i]\n",
    "    \n",
    "    probtwerel = probPal * probrel\n",
    "    \n",
    "    probtweirr = ProbPal * probirr\n",
    "    \n",
    "    if probtwerel > probtweirr:\n",
    "        return \"R\"\n",
    "    else:\n",
    "        return \"I\"\n",
    "\n",
    "\n",
    "teste[\"Classificado\"] = teste[\"Separado\"].apply(verifica_relevancia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu Classificador com a base de Testes.<br /><br /> \n",
    "\n",
    "Você deve extrair as seguintes medidas:\n",
    "* Porcentagem de positivos falsos (marcados como relevante mas não são relevantes)\n",
    "* Porcentagem de positivos verdadeiros (marcado como relevante e são relevantes)\n",
    "* Porcentagem de negativos verdadeiros (marcado como não relevante e não são relevantes)\n",
    "* Porcentagem de negativos falsos (marcado como não relevante e são relevantes)\n",
    "\n",
    "Obrigatório para grupos de 3 alunos:\n",
    "* Criar categorias intermediárias de relevância baseado na diferença de probabilidades. Exemplo: muito relevante, relevante, neutro, irrelevante e muito irrelevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estatísticas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negver</th>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>posver</th>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negfal</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>posfal</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Estatísticas\n",
       "negver           123\n",
       "posver            57\n",
       "negfal            10\n",
       "posfal            10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def classificação(i):\n",
    "    temp = teste[teste.index == i]\n",
    "    if temp[\"Classificado\"].values[0] == \"I\":\n",
    "        if temp[\"Relevância\"].values[0] == temp[\"Classificado\"].values[0]:\n",
    "            return \"negver\"\n",
    "        return \"negfal\"\n",
    "\n",
    "    if temp[\"Relevância\"].values[0] == temp[\"Classificado\"].values[0]:\n",
    "        return \"posver\"\n",
    "    return \"posfal\"\n",
    "\n",
    "stats = pd.Series(teste.index).apply(classificação).value_counts()\n",
    "\n",
    "All = stats.sum()\n",
    "\n",
    "stats.to_frame().rename(columns={0:\"Estatísticas\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A porcentagem de positivos verdadeiros é 28.5%.\n",
      "A porcentagem de falsos positivos é 5.0%.\n",
      "A porcentagem de negativos verdadeiros é 61.5%.\n",
      "A porcentagem de falsos negativos é 5.0%.\n",
      "\n",
      "\n",
      "O erro do classificador é de 10.0%.\n"
     ]
    }
   ],
   "source": [
    "print(\"A porcentagem de positivos verdadeiros é {:.1f}%.\".format(stats[\"posver\"] * 100/All))\n",
    "print(\"A porcentagem de falsos positivos é {:.1f}%.\"     .format(stats[\"posfal\"] * 100/All))\n",
    "print(\"A porcentagem de negativos verdadeiros é {:.1f}%.\".format(stats[\"negver\"] * 100/All))\n",
    "print(\"A porcentagem de falsos negativos é {:.1f}%.\"     .format(stats[\"negfal\"] * 100/All))\n",
    "print(\"\\n\")\n",
    "print(\"O erro do classificador é de {:.1f}%.\".format((stats[\"negfal\"] + stats[\"posfal\"]) * 100/All))\n",
    "\n",
    "# A porcentagem de positivos verdadeiros é 28.5%.\n",
    "# A porcentagem de falsos positivos é 5.0%.\n",
    "# A porcentagem de negativos verdadeiros é 61.5%.\n",
    "# A porcentagem de falsos negativos é 5.0%.\n",
    "\n",
    "\n",
    "# O erro do classificador é de 10.0%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Concluindo\n",
    "\n",
    "Escreva aqui a sua conclusão.<br /> \n",
    "Faça um comparativo qualitativo sobre as medidas obtidas.<br />\n",
    "Explique como são tratadas as mensagens com dupla negação e sarcasmo.<br />\n",
    "Proponha um plano de expansão. Por que eles devem continuar financiando o seu projeto?<br />\n",
    "\n",
    "Opcionalmente: \n",
    "* Discorrer por que não posso alimentar minha base de Treinamento automaticamente usando o próprio classificador, aplicado a novos tweets.\n",
    "* Propor diferentes cenários de uso para o classificador Naive-Bayes. Cenários sem intersecção com este projeto.\n",
    "* Sugerir e explicar melhorias reais no classificador com indicações concretas de como implementar (não é preciso codificar, mas indicar como fazer e material de pesquisa sobre o assunto).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dupla negacao\n",
    "verifica_relevancia(\"I didn't hate spiderman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'O código rodou em 286.63 segundos após de importar o pandar e ler os excels'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"O código rodou em {time()-tempo_incial:.2f} segundos após de importar o pandar e ler os excels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
